---
title: "ğŸ” å·ç§¯ç¥ç»ç½‘ç»œ"
outline: deep

tags: "deepLearning"
updateTime: "2024-12-2 17:52"
---
![wind](../../public/img_book/wind.png)
>å‹åŠ›å¤ªå¤§çš„æ—¶å€™ï¼Œä¸å¦¨å¹å¹æ™šé£ã€‚
### å·ç§¯ç¥ç»ç½‘ç»œ

***

#### å·ç§¯åŸºç¡€ç¯‡

ä¸€ä¸ªåŸºæœ¬çš„å·ç§¯ç¥ç»ç½‘ç»œå›¾ï¼š**è¾“å…¥å±‚->n*(å·ç§¯->æ± åŒ–)->å…¨è¿æ¥å±‚->è¾“å‡ºå±‚**

![image-20241202170457351](../../public/asserts/CNN.png)


##### å·ç§¯å±‚
å·ç§¯è¿‡ç¨‹ï¼šç”¨ä¸€ä¸ªå·ç§¯æ ¸åœ¨rgb/ç°åº¦å›¾åƒä¸Šéå†ï¼Œå°†å¯¹åº”æ•°å­—ç›¸ä¹˜å†ç›¸åŠ ï¼Œ**å·ç§¯æ ¸çš„channelæ•°ï¼Œç”±å•ä¸ªæ ·æœ¬çš„channelæ•°å†³å®š**ï¼Œæœ€ç»ˆè¾“å‡ºçš„æ˜¯å•å±‚ï¼Œ**è‹¥æƒ³è¦nå±‚é€šé“ï¼Œåˆ™éœ€è¦nä¸ªè¿™æ ·çš„å·ç§¯æ ¸**

![image-20241202171032364](../../public/asserts/Conv.png)

*æµ‹è¯•ä»£ç *

```py
import torch
import  torch.nn  as nn



in_channel,out_channer=5,10
width,height=100,100
kernel_size=3
batch_size=1
input = torch.randn(batch_size,in_channel,width,height)
layer=nn.Conv2d(in_channel,out_channer,kernel_size=kernel_size)
output=layer(input)
print(input.shape)
print(output.shape)
print(layer.weight.shape)
```



å¯ä»¥å¾—å‡ºï¼Œä¸€ä¸ªnxnè¾“å…¥ç»è¿‡å·ç§¯æ ¸åï¼Œå®½é«˜å˜æˆ**n+1-kernel_size**ï¼Œè‹¥æƒ³ä¸æ”¹å˜å½¢çŠ¶ï¼Œå¯ä»¥é€šè¿‡ç»™è¾“å…¥å¢åŠ paddingå±‚

*æµ‹è¯•ä»£ç *

```py
import  torch.nn as nn
import  torch
# å¤šåŠ ä¸€ä¸ªpaddingï¼Œå®ç°ç»è¿‡å·ç§¯æ ¸ä¸æ”¹å˜å½¢çŠ¶


in_channel,out_channer=1,1
width,height=5,5
kernel_size=3
batch_size=1
input = torch.randn(batch_size,in_channel,width,height)
# åœ¨åŸæœ¬çš„åŸºç¡€ä¸ŠåŠ ä¸Špadding=1å’Œè®¾ç½®åç½®é‡ä¸º0
layer=nn.Conv2d(in_channel,out_channer,kernel_size=kernel_size,padding=1,bias=False)
# é™¤äº†å¯ä»¥è®¾ç½®paddingä¹‹å¤–ï¼Œè¿˜å¯ä»¥è®¾ç½®æ­¥é•¿strideï¼Œæ§åˆ¶å·ç§¯æ ¸éå†æ—¶ä¸€æ¬¡ç§»åŠ¨çš„è·ç¦»
# layer=nn.Conv2d(in_channel,out_channer,kernel_size=kernel_size,stride=2,bias=False)
kernel=torch.tensor([1,2,3,4,5,6,7,8,9],dtype=torch.float32).view(1,1,3,3)
layer.weight.data=kernel
output=layer(input)
print(output)
print(output.shape)
```


##### æ± åŒ–å±‚
 **æ± åŒ–å±‚**ï¼šå¸¸ç”¨æœ€å¤§æ± åŒ–å’Œå‡å€¼æ± åŒ–ï¼ŒåŒæ ·å¯è®¾ç½®æ­¥é•¿å’Œpaddingï¼Œé»˜è®¤æ­¥é•¿ä¸kernel_sizeç›¸åŒ

![image-20241202172001878](../../public/asserts/Pool.png)

##### åŸºç¡€å·ç§¯ä»£ç å®ç°ministåˆ†ç±»

```py
import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import torch.nn as nn
import torch.nn.functional as F


# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# åŠ è½½æ•°æ®é›†
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)



class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        # ä¸€çº§å·ç§¯å±‚å°†channelæ‰©å¤§åˆ°10
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        # äºŒçº§è¿›ä¸€æ­¥æ‰©å¤§
        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)
        # å®šä¹‰æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(2)
        # å…¨è¿æ¥å±‚å°†320å‹ç¼©ä¸º10ä¸ªè¾“å‡º
        self.fc = nn.Linear(320, 10)

    def forward(self, x):
        batch_size = x.size(0)
        # ç¬¬ä¸€æ¬¡å·ç§¯æ± åŒ–
        x = F.relu(self.pool(self.conv1(x)))
        # ç¬¬äºŒæ¬¡å·ç§¯æ± åŒ–
        x = F.relu(self.pool(self.conv2(x)))
        # å±•å¹³å¹¶è¿›å…¥å…¨è¿æ¥å±‚
        x = x.view(batch_size, -1)
        x = self.fc(x)
        return x


# pytorchä¸­è°ƒç”¨gpuçš„æ–¹æ³•
model = Net()
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model.to(device)
# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# è®­ç»ƒå‡½æ•°
def train(epoch):
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    running_loss = 0.0
    for batch_idx, data in enumerate(train_loader, 0):
        inputs, target = data
        inputs, target = inputs.to(device), target.to(device)
        optimizer.zero_grad()
        # å‰å‘ä¼ æ’­è·å¾—è¾“å‡ºï¼Œè®¡ç®—æŸå¤±å€¼
        outputs = model(inputs)
        loss = criterion(outputs, target)
        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        loss.backward()
        # æ›´æ–°æ¢¯åº¦
        optimizer.step()

        running_loss += loss.item()
        if batch_idx % 300 == 299:  # æ¯300ä¸ªæ‰¹æ¬¡è¾“å‡ºä¸€æ¬¡æŸå¤±
            print(f'[{epoch + 1}, {batch_idx + 1}] loss: {running_loss / 300:.3f}')
            running_loss = 0.0

# æµ‹è¯•å‡½æ•°
def test():
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    correct = 0
    total = 0
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for data in test_loader:
            inputs, target = data
            inputs, target = inputs.to(device), target.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    print(f'Accuracy on test set: {100 * correct / total:.2f}% [{correct}/{total}]')

if __name__ == '__main__':
    for epoch in range(10):  # è®­ç»ƒ10ä¸ªepoch
        train(epoch)
        if(epoch%10==9):
            test()

```

ä¸Šè¿°é¢„å¤„ç†ä¸­ç”¨åˆ°çš„transforms.ToTensor()ä½œç”¨ï¼šå°†å›¾åƒåƒç´ å½’ä¸€åŒ–ï¼ŒåŒæ—¶å˜æˆå¸¦æœ‰channelæ•°çš„å¼ é‡

**PILæ˜¯pyè‡ªå¸¦çš„å¤„ç†å›¾åƒå·¥å…·**

![å±å¹•æˆªå›¾ 2024-12-02 112122](../../public/asserts/ToTensor.png)





#### å·ç§¯é«˜çº§ç¯‡

***

ä¹‹å‰å†™çš„æ˜¯æœ€åŸºç¡€çš„å·ç§¯ç½‘ç»œï¼Œéƒ½æ˜¯å·ç§¯å±‚å’Œæ± åŒ–å±‚ä¸²è¡Œçš„ã€‚
ä¸‹é¢ä»‹ç»æ›´é«˜çº§çš„å·ç§¯ç½‘ç»œï¼Œä»¥ä¸‹æ˜¯googleNetçš„å®ç°

##### GoogleNet

###### Inception

é¦–å…ˆéœ€è¦å°è£…ä¸€ä¸ªå¤šæ¬¡ä½¿ç”¨çš„æ¨¡å—inception
inceptionè§£å†³çš„é—®é¢˜æ˜¯ç»™å‡ºå¤šæ¡å·ç§¯æ ¸ç»„åˆè·¯å¾„ï¼Œæœ€ç»ˆè®­ç»ƒæ•ˆæœæœ€å¥½çš„è·¯å¾„æƒé‡è‚¯å®šä¼šæœ€é«˜ï¼Œä»è€Œæ‰¾åˆ°æœ€é€‚å·ç§¯å±‚ç»„åˆ

![å±å¹•æˆªå›¾ 2024-12-02 140437](../../public/asserts/Inception.png)

##### googleNetå®ç°minist

```py

import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import torch.nn as nn
import torch.nn.functional as F


# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# åŠ è½½æ•°æ®é›†
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)



class Inception(nn.Module):
    def __init__(self,in_channels):
        super(Inception,self).__init__()
        #åˆå§‹åŒ–å±‚
        self.branch_pool=nn.Conv2d(in_channels,24,kernel_size=1)

        self.branch1x1=nn.Conv2d(in_channels,16,kernel_size=1)

        self.branch5x5_1=nn.Conv2d(in_channels,16,kernel_size=1)
        self.branch5x5_2=nn.Conv2d(16,24,kernel_size=5,padding=2)

        self.branch3x3_1=nn.Conv2d(in_channels,16,kernel_size=1)
        self.branch3x3_2=nn.Conv2d(16,24,kernel_size=3,padding=1)
        self.branch3x3_3=nn.Conv2d(24,24,kernel_size=3,padding=1)

    def forward(self,x):
        #åˆ†æ”¯ä»å·¦åˆ°å³ï¼Œä¾æ¬¡å®ç°
        # strideè‹¥ä¸è®¾ç½®ï¼Œåˆ™é»˜è®¤ä¸æ± åŒ–ç›’å¤§å°ç›¸ç­‰ï¼Œä¼šé€ æˆå®½é«˜ä¸ä¸€è‡´
        branch_pool=F.avg_pool2d(x,kernel_size=3,padding=1,stride=1)
        branch_pool=self.branch_pool(branch_pool)

        branch_1x1=self.branch1x1(x)

        branch_5x5=self.branch5x5_1(x)
        branch_5x5=self.branch5x5_2(branch_5x5)

        branch_3x3=self.branch3x3_1(x)
        branch_3x3=self.branch3x3_2(branch_3x3)
        branch_3x3=self.branch3x3_3(branch_3x3)

        outputs=[branch_pool,branch_1x1,branch_5x5,branch_3x3]
        return torch.cat(outputs,dim=1)
class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)
        # 88=24+16+24+24
        self.conv2 = nn.Conv2d(88, 20, kernel_size=5)
        #ä¸¤ä¸ªinception
        self.incep1=Inception(10)
        self.incep2=Inception(20)
        # å®šä¹‰æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(2)
        # ministæ•°æ®é›†28x28,å·ç§¯ä¸€æ¬¡-4=24ï¼Œæ± åŒ–12ï¼Œå†å·ç§¯ä¸€æ¬¡-4=8ï¼Œæ± åŒ–4ï¼Œæ‰€ä»¥æœ€ç»ˆå¾—åˆ°çš„æ˜¯88x4x4,å±•å¹³ä¸º1408
        self.fc = nn.Linear(1408, 10)
    def forward(self,x):
        in_size=x.size(0)
        x=F.relu(self.pool(self.conv1(x)))
        x=self.incep1(x)
        x=F.relu(self.pool(self.conv2(x)))
        x=self.incep2(x)
        x=x.view(in_size,-1)
        return self.fc(x)

# pytorchä¸­è°ƒç”¨gpuçš„æ–¹æ³•
model = Net()
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model.to(device)
# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# è®­ç»ƒå‡½æ•°
def train(epoch):
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    running_loss = 0.0
    for batch_idx, data in enumerate(train_loader, 0):
        inputs, target = data
        inputs, target = inputs.to(device), target.to(device)
        optimizer.zero_grad()
        # å‰å‘ä¼ æ’­è·å¾—è¾“å‡ºï¼Œè®¡ç®—æŸå¤±å€¼
        outputs = model(inputs)
        loss = criterion(outputs, target)
        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        loss.backward()
        # æ›´æ–°æ¢¯åº¦
        optimizer.step()

        running_loss += loss.item()
        if batch_idx % 300 == 299:  # æ¯300ä¸ªæ‰¹æ¬¡è¾“å‡ºä¸€æ¬¡æŸå¤±
            print(f'[{epoch + 1}, {batch_idx + 1}] loss: {running_loss / 300:.3f}')
            running_loss = 0.0

# æµ‹è¯•å‡½æ•°
def test():
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    correct = 0
    total = 0
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for data in test_loader:
            inputs, target = data
            inputs, target = inputs.to(device), target.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    print(f'Accuracy on test set: {100 * correct / total:.2f}% [{correct}/{total}]')

if __name__ == '__main__':
    for epoch in range(10):  # è®­ç»ƒ10ä¸ªepoch
        train(epoch)
        if(epoch%10==9):
            test()

```

##### Residual

- åŠ å…¥æ®‹å·®å—
- åœ¨æ¿€æ´»ä¹‹å‰ï¼Œå…ˆåŠ ä¸Šå·ç§¯ä¹‹åçš„è¾“å‡ºï¼Œè¿™æ ·æ±‚å¯¼ä¹‹åä¼šåœ¨1çš„åŸºç¡€ä¸ŠåŠ ä¸ŠåŸæ¥çš„å¯¼æ•°ï¼Œè¿™æ ·å³ä½¿æ±‚å¯¼éƒ½æ˜¯<1çš„æ•°ç»è¿‡ç´¯ä¹˜ä¹Ÿä¸ä¼šå¾ˆå°ï¼Œä»è€Œé¿å…äº†æ¢¯åº¦æ¶ˆå¤±
- èƒ½è®©å‰é¢çš„å±‚æœ‰æ›´å¥½çš„è®­ç»ƒ

![å±å¹•æˆªå›¾ 2024-12-02 163714](../../public/asserts/Res.png)

##### Residualå®ç°minist

```py


import torch
from torch.utils.data import DataLoader
from torchvision import datasets, transforms

import torch.nn as nn
import torch.nn.functional as F


# æ•°æ®é¢„å¤„ç†
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])

# åŠ è½½æ•°æ®é›†
train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)

test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)
test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)


# å®šä¹‰æ®‹å·®å—
class Residual(nn.Module):
    def __init__(self,in_channels):
        super(Residual,self).__init__()
        #è¦ä¿è¯èƒ½ç›¸åŠ ï¼Œå°±è¦ä¿è¯xç»è¿‡æ®‹å·®å—åï¼Œchannelçš„å€¼å’Œå®½é«˜éƒ½ä¸ä¼šå‘ç”Ÿæ”¹å˜
        self.conv1=nn.Conv2d(in_channels,in_channels,kernel_size=3,padding=1)
        self.conv2=nn.Conv2d(in_channels,in_channels,kernel_size=3,padding=1)
    def forward(self,x):
        y=F.relu(self.conv1(x))
        y=self.conv2(y)
        return F.relu(x+y)


class Net(nn.Module):
    def __init__(self):
        super(Net,self).__init__()
        self.conv1 = nn.Conv2d(1, 16, kernel_size=5)
        # 88=24+16+24+24
        self.conv2 = nn.Conv2d(16, 32, kernel_size=5)
        #ä¸¤ä¸ªinception
        self.res1=Residual(16)
        self.res2=Residual(32)
        # å®šä¹‰æ± åŒ–å±‚
        self.pool = nn.MaxPool2d(2)
        # ministæ•°æ®é›†28x28,å·ç§¯ä¸€æ¬¡-4=24ï¼Œæ± åŒ–12ï¼Œå†å·ç§¯ä¸€æ¬¡-4=8ï¼Œæ± åŒ–4ï¼Œæ®‹å·®å—ä¸ä¼šæ”¹å˜å½¢çŠ¶ä¸ç”¨è€ƒè™‘ï¼Œæ‰€ä»¥æœ€ç»ˆå¾—åˆ°çš„æ˜¯32x4x4,å±•å¹³ä¸º512
        self.fc = nn.Linear(512, 10)
    def forward(self,x):
        in_size=x.size(0)
        x=F.relu(self.pool(self.conv1(x)))
        x=self.res1(x)
        x=F.relu(self.pool(self.conv2(x)))
        x=self.res2(x)
        x=x.view(in_size,-1)
        return self.fc(x)

# pytorchä¸­è°ƒç”¨gpuçš„æ–¹æ³•
model = Net()
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
model.to(device)
# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

# è®­ç»ƒå‡½æ•°
def train(epoch):
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    running_loss = 0.0
    for batch_idx, data in enumerate(train_loader, 0):
        inputs, target = data
        inputs, target = inputs.to(device), target.to(device)
        optimizer.zero_grad()
        # å‰å‘ä¼ æ’­è·å¾—è¾“å‡ºï¼Œè®¡ç®—æŸå¤±å€¼
        outputs = model(inputs)
        loss = criterion(outputs, target)
        # åå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦
        loss.backward()
        # æ›´æ–°æ¢¯åº¦
        optimizer.step()

        running_loss += loss.item()
        if batch_idx % 300 == 299:  # æ¯300ä¸ªæ‰¹æ¬¡è¾“å‡ºä¸€æ¬¡æŸå¤±
            print(f'[{epoch + 1}, {batch_idx + 1}] loss: {running_loss / 300:.3f}')
            running_loss = 0.0

# æµ‹è¯•å‡½æ•°
def test():
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    correct = 0
    total = 0
    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦
        for data in test_loader:
            inputs, target = data
            inputs, target = inputs.to(device), target.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()
    print(f'Accuracy on test set: {100 * correct / total:.2f}% [{correct}/{total}]')

if __name__ == '__main__':
    for epoch in range(10):  # è®­ç»ƒ10ä¸ªepoch
        train(epoch)
        if(epoch%10==9):
            test()

```